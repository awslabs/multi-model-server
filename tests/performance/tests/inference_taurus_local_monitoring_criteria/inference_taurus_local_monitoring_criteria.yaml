---
execution:
- concurrency: 1
  ramp-up: 5s
  hold-for: 20s
  scenario: Inference

scenarios:
  Inference:
    script: register_and_inference.jmx

modules:
  server_local_monitoring:
    # metrics_monitoring_taurus and dependencies should be in python path
    class : metrics_monitoring_taurus.Monitor # monitoring class.

services:
  - module: shellexec
    prepare:
      - "curl -s -O https://s3.amazonaws.com/model-server/inputs/kitten.jpg"
      - "multi-model-server --start > /dev/null 2>&1"
      - "sleep 10s"
    post-process:
      - "multi-model-server --stop > /dev/null 2>&1"
      - "rm kitten.jpg"
  - module: server_local_monitoring # should be added in modules section
    ServerLocalClient: # keyword from metrics_monitoring_taurus.Monitor
    - interval: 1s
      logging : True
      metrics:
        - cpu
        - disk-space
        - mem
        - sum_workers_memory_rss

reporting:
- module: passfail
  criteria:
    - fail >${fail}, stop as failed
    - p90 >${p90}  , stop as failed
    - avg-rt >${avg_rt} , stop as failed
    - class: bzt.modules.monitoring.MonitoringCriteria
      subject: ServerLocalClient/sum_workers_memory_rss
      condition: '>'
      threshold: ${sum_workers_memory_rss}
      timeframe: 1s
      stop : true
      fail : true
      diff_percent : ${sum_workers_memory_rss_diff_percent}
