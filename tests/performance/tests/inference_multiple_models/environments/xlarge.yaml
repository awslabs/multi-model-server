
---
settings:
  env:
    API_LABEL : Inference1
    API_SUCCESS : 80%
    API_AVG_RT : 30ms

    INFR2_SUCC: 100%
    INFR2_RT: 450ms

    TOTAL_WORKERS: 2
    TOTAL_WORKERS_MEM: 600000000
    TOTAL_WORKERS_FDS: 150

    TOTAL_MEM : 1400000000
    TOTAL_PROCS : 3
    TOTAL_FDS : 150

    FRNTEND_MEM: 800000000

    TOTAL_ORPHANS : 0
    TOTAL_ZOMBIES : 0

    TOTAL_WORKERS_PREV_DIFF: 30
    TOTAL_WORKERS_MEM_PREV_DIFF: 30
    TOTAL_WORKERS_FDS_PREV_DIFF: 30
    TOTAL_MEM_PREV_DIFF: 30
    TOTAL_PROCS_PREV_DIFF: 30
    TOTAL_FDS_PREV_DIFF: 30
    FRNTEND_MEM_PREV_DIFF: 30
    TOTAL_ORPHANS_PREV_DIFF: 0
    TOTAL_ZOMBIES_PREV_DIFF: 0

    TOTAL_WORKERS_RUN_DIFF: 30
    TOTAL_WORKERS_MEM_RUN_DIFF: 30
    TOTAL_WORKERS_FDS_RUN_DIFF: 30
    TOTAL_MEM_RUN_DIFF: 30
    TOTAL_PROCS_RUN_DIFF: 30
    TOTAL_FDS_RUN_DIFF: 30
    FRNTEND_MEM_RUN_DIFF: 40
    TOTAL_ORPHANS_RUN_DIFF: 0
    TOTAL_ZOMBIES_RUN_DIFF: 0

    CONCURRENCY : 10
    RAMP-UP : 1s
    HOLD-FOR : 300s
    SCRIPT : inference_multiple_models.jmx

    STOP :  ''    #possible values true, false. Bug in bzt so for false use ''
    STOP_ALIAS: continue  #possible values continue, stop